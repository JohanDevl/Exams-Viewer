---
alwaysApply: true
---

# Cursor Rules for Exams-Viewer Project

## Project Overview

This is an automated exam questions scraper and viewer for ExamTopics.com with a web interface.

## Technology Stack

- **Frontend**: Vanilla JavaScript, HTML5, CSS3
- **Backend**: Python 3.x with requests, BeautifulSoup4
- **Data Storage**: JSON files
- **Automation**: GitHub Actions
- **Deployment**: GitHub Pages

## Code Style Guidelines

### JavaScript (script.js)

- Use ES6+ features (const/let, arrow functions, async/await)
- Maintain alphabetical ordering for exam lists (critical requirement)
- Follow camelCase naming convention
- Use descriptive variable names
- Add JSDoc comments for complex functions
- Prefer async/await over Promises for readability
- Use template literals for string interpolation

### Python (scripts/)

- Follow PEP 8 style guidelines
- Use type hints where appropriate
- Maintain consistent error handling patterns
- Use descriptive function and variable names
- Add docstrings for all functions
- Prefer f-strings for string formatting
- Handle exceptions gracefully with specific error messages

### HTML (index.html)

- Use semantic HTML5 elements
- Maintain proper indentation (2 spaces)
- Include appropriate ARIA labels for accessibility
- Use Font Awesome icons consistently
- Keep structure clean and organized

### CSS (styles.css)

- Use CSS custom properties (variables) for consistent theming
- Follow BEM methodology for class naming
- Maintain responsive design principles
- Use flexbox/grid for layouts
- Keep vendor prefixes for compatibility
- Support dark mode using CSS custom properties and prefers-color-scheme media queries

## Architecture Patterns

### Frontend Architecture

- **State Management**: Global state variables for current exam, questions, and UI state
- **Event Handling**: Centralized event listener setup in setupEventListeners()
- **Data Flow**: Async data loading → state update → UI rendering
- **Error Handling**: Centralized error/success message display functions

### Backend Architecture

- **Scraping Logic**: Modular functions for different scraping phases
- **Data Persistence**: JSON file storage with atomic updates
- **Rate Limiting**: Built-in delays to respect server limits
- **Progress Tracking**: Callback-based progress reporting

## Key Requirements

### Critical Business Rules

1. **Exam lists MUST be displayed in alphabetical order** (stored in memory)
2. Questions must be sorted numerically by question_number
3. Maintain backward compatibility with existing JSON data format
4. Respect ExamTopics.com rate limits (5-10 second delays)

### Data Integrity

- Always validate JSON structure before processing
- Handle missing or malformed data gracefully
- Maintain consistent data format across all exam files
- Implement proper error states and recovery

### User Experience

- Provide loading states for all async operations
- Show clear error messages with actionable information
- Maintain responsive design for mobile devices
- Implement keyboard shortcuts for navigation
- Export functionality must work across browsers

## File Structure Conventions

### Data Files

- `{EXAM_CODE}.json`: Main exam data with questions
- `{EXAM_CODE}_links.json`: Question links and scraping metadata
- All exam codes should be uppercase (e.g., "CIS-ITSM", "CAD")

### Script Organization

- `scraper.py`: Core scraping logic and utilities
- `update_all_exams.py`: Automation and batch processing
- Keep scripts focused on single responsibilities

## Development Practices

### Testing Approach

- Test with multiple exam codes to ensure compatibility
- Verify alphabetical sorting in all exam list displays
- Test error handling with malformed data
- Validate export functionality across browsers

### Performance Considerations

- Use HEAD requests for existence checks
- Implement parallel processing where safe
- Cache exam metadata to reduce API calls
- Optimize DOM manipulation in frontend

### Security Guidelines

- Sanitize all user inputs in frontend
- Use proper HTTP headers in scraping requests
- Validate all external data before processing
- Implement proper error boundaries

## Common Patterns

### Async Data Loading

```javascript
async function loadExam(examCode) {
  showLoading(true);
  try {
    const response = await fetch(`data/${examCode}.json`);
    if (!response.ok) throw new Error(`Failed to load: ${response.status}`);
    const data = await response.json();
    // Process data...
  } catch (error) {
    showError(`Error loading exam: ${error.message}`);
  } finally {
    showLoading(false);
  }
}
```

### Python Error Handling

```python
def scrape_page(link):
    try:
        response = requests.get(link, headers=HEADERS)
        response.raise_for_status()
        # Process response...
    except Exception as e:
        return {"error": f"Request failed: {e}"}
```

### Alphabetical Sorting (Critical)

```javascript
// Always sort exam lists alphabetically
const sortedExamCodes = Object.keys(availableExams).sort();
examOptions.sort((a, b) => a.code.localeCompare(b.code));
```

## Debugging Guidelines

### Frontend Debugging

- Use browser DevTools Network tab for API issues
- Check console for JavaScript errors
- Verify JSON data structure in browser
- Test responsive design in device emulation

### Backend Debugging

- Add detailed logging for scraping operations
- Use try-catch blocks with specific error messages
- Validate data at each processing step
- Monitor rate limiting and response times

## Deployment Considerations

### GitHub Pages

- Ensure all paths are relative
- Test with GitHub Pages URL structure
- Verify CORS settings for data loading
- Maintain compatibility with GitHub's Jekyll processing

### GitHub Actions

- Use appropriate timeouts for long-running operations
- Implement proper error reporting in workflows
- Maintain secrets for any required credentials
- Test workflow triggers and schedules

## Code Review Checklist

- [ ] Exam lists are sorted alphabetically
- [ ] Error handling is implemented
- [ ] Loading states are shown for async operations
- [ ] Data validation is performed
- [ ] Rate limiting is respected in scraping
- [ ] Responsive design is maintained
- [ ] Accessibility features are preserved
- [ ] JSON data format is consistent
- [ ] Performance optimizations are applied
- [ ] Security best practices are followed
- [ ] Dark mode is supported

## Common Issues and Solutions

### Frontend Issues

- **Exam list not alphabetical**: Check sorting in populateExamDropdown() and displayAvailableExams()
- **Questions not loading**: Verify JSON file exists and has correct structure
- **Export not working**: Check browser compatibility and PDF generation logic

### Backend Issues

- **Scraping failures**: Check rate limits and website structure changes
- **Data corruption**: Implement atomic file writes and validation
- **Performance issues**: Review request patterns and implement caching

## Dependencies Management

### Frontend Dependencies

- Font Awesome 6.0.0 (CDN)
- No build process required - vanilla JavaScript

### Backend Dependencies

- requests: HTTP client for scraping
- beautifulsoup4: HTML parsing
- json: Data serialization (built-in)

Keep dependencies minimal and well-documented in requirements.txt.

# Cursor Rules for Exams-Viewer Project

## Project Overview

This is an automated exam questions scraper and viewer for ExamTopics.com with a web interface.

## Technology Stack

- **Frontend**: Vanilla JavaScript, HTML5, CSS3
- **Backend**: Python 3.x with requests, BeautifulSoup4
- **Data Storage**: JSON files
- **Automation**: GitHub Actions
- **Deployment**: GitHub Pages

## Code Style Guidelines

### JavaScript (script.js)

- Use ES6+ features (const/let, arrow functions, async/await)
- Maintain alphabetical ordering for exam lists (critical requirement)
- Follow camelCase naming convention
- Use descriptive variable names
- Add JSDoc comments for complex functions
- Prefer async/await over Promises for readability
- Use template literals for string interpolation

### Python (scripts/)

- Follow PEP 8 style guidelines
- Use type hints where appropriate
- Maintain consistent error handling patterns
- Use descriptive function and variable names
- Add docstrings for all functions
- Prefer f-strings for string formatting
- Handle exceptions gracefully with specific error messages

### HTML (index.html)

- Use semantic HTML5 elements
- Maintain proper indentation (2 spaces)
- Include appropriate ARIA labels for accessibility
- Use Font Awesome icons consistently
- Keep structure clean and organized

### CSS (styles.css)

- Use CSS custom properties (variables) for consistent theming
- Follow BEM methodology for class naming
- Maintain responsive design principles
- Use flexbox/grid for layouts
- Keep vendor prefixes for compatibility

## Architecture Patterns

### Frontend Architecture

- **State Management**: Global state variables for current exam, questions, and UI state
- **Event Handling**: Centralized event listener setup in setupEventListeners()
- **Data Flow**: Async data loading → state update → UI rendering
- **Error Handling**: Centralized error/success message display functions

### Backend Architecture

- **Scraping Logic**: Modular functions for different scraping phases
- **Data Persistence**: JSON file storage with atomic updates
- **Rate Limiting**: Built-in delays to respect server limits
- **Progress Tracking**: Callback-based progress reporting

## Key Requirements

### Critical Business Rules

1. **Exam lists MUST be displayed in alphabetical order** (stored in memory)
2. Questions must be sorted numerically by question_number
3. Maintain backward compatibility with existing JSON data format
4. Respect ExamTopics.com rate limits (5-10 second delays)

### Data Integrity

- Always validate JSON structure before processing
- Handle missing or malformed data gracefully
- Maintain consistent data format across all exam files
- Implement proper error states and recovery

### User Experience

- Provide loading states for all async operations
- Show clear error messages with actionable information
- Maintain responsive design for mobile devices
- Implement keyboard shortcuts for navigation
- Export functionality must work across browsers

## File Structure Conventions

### Data Files

- `{EXAM_CODE}.json`: Main exam data with questions
- `{EXAM_CODE}_links.json`: Question links and scraping metadata
- All exam codes should be uppercase (e.g., "CIS-ITSM", "CAD")

### Script Organization

- `scraper.py`: Core scraping logic and utilities
- `update_all_exams.py`: Automation and batch processing
- Keep scripts focused on single responsibilities

## Development Practices

### Testing Approach

- Test with multiple exam codes to ensure compatibility
- Verify alphabetical sorting in all exam list displays
- Test error handling with malformed data
- Validate export functionality across browsers

### Performance Considerations

- Use HEAD requests for existence checks
- Implement parallel processing where safe
- Cache exam metadata to reduce API calls
- Optimize DOM manipulation in frontend

### Security Guidelines

- Sanitize all user inputs in frontend
- Use proper HTTP headers in scraping requests
- Validate all external data before processing
- Implement proper error boundaries

## Common Patterns

### Async Data Loading

```javascript
async function loadExam(examCode) {
  showLoading(true);
  try {
    const response = await fetch(`data/${examCode}.json`);
    if (!response.ok) throw new Error(`Failed to load: ${response.status}`);
    const data = await response.json();
    // Process data...
  } catch (error) {
    showError(`Error loading exam: ${error.message}`);
  } finally {
    showLoading(false);
  }
}
```

### Python Error Handling

```python
def scrape_page(link):
    try:
        response = requests.get(link, headers=HEADERS)
        response.raise_for_status()
        # Process response...
    except Exception as e:
        return {"error": f"Request failed: {e}"}
```

### Alphabetical Sorting (Critical)

```javascript
// Always sort exam lists alphabetically
const sortedExamCodes = Object.keys(availableExams).sort();
examOptions.sort((a, b) => a.code.localeCompare(b.code));
```

## Debugging Guidelines

### Frontend Debugging

- Use browser DevTools Network tab for API issues
- Check console for JavaScript errors
- Verify JSON data structure in browser
- Test responsive design in device emulation

### Backend Debugging

- Add detailed logging for scraping operations
- Use try-catch blocks with specific error messages
- Validate data at each processing step
- Monitor rate limiting and response times

## Deployment Considerations

### GitHub Pages

- Ensure all paths are relative
- Test with GitHub Pages URL structure
- Verify CORS settings for data loading
- Maintain compatibility with GitHub's Jekyll processing

### GitHub Actions

- Use appropriate timeouts for long-running operations
- Implement proper error reporting in workflows
- Maintain secrets for any required credentials
- Test workflow triggers and schedules

## Code Review Checklist

- [ ] Exam lists are sorted alphabetically
- [ ] Error handling is implemented
- [ ] Loading states are shown for async operations
- [ ] Data validation is performed
- [ ] Rate limiting is respected in scraping
- [ ] Responsive design is maintained
- [ ] Accessibility features are preserved
- [ ] JSON data format is consistent
- [ ] Performance optimizations are applied
- [ ] Security best practices are followed

## Common Issues and Solutions

### Frontend Issues

- **Exam list not alphabetical**: Check sorting in populateExamDropdown() and displayAvailableExams()
- **Questions not loading**: Verify JSON file exists and has correct structure
- **Export not working**: Check browser compatibility and PDF generation logic

### Backend Issues

- **Scraping failures**: Check rate limits and website structure changes
- **Data corruption**: Implement atomic file writes and validation
- **Performance issues**: Review request patterns and implement caching

## Dependencies Management

### Frontend Dependencies

- Font Awesome 6.0.0 (CDN)
- No build process required - vanilla JavaScript

### Backend Dependencies

- requests: HTTP client for scraping
- beautifulsoup4: HTML parsing
- json: Data serialization (built-in)

Keep dependencies minimal and well-documented in requirements.txt.
